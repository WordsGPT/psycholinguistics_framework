experiments:
  original:
    dataset_path: "path/to/original/dataset.csv"
    dataset_column: "Name of the column containing the words"
    prompt_path: "path/to/prompt.txt"
    model_name: "OpenAI model name, e.g., gpt-4o-mini-2024-07-18"
    company: "OpenAI"
    #ft_dir: "" # for local fine-tunings

  experiment-ft-v1:
    dataset_path: "path/to/original/dataset.csv"
    dataset_column: "Name of the column containing the words"
    prompt_path: "path/to/prompt.txt"
    # prompt_assistant_path: ""
    model_name: "OpenAI fine-tuned model name, e.g., ft:gpt-4o-mini-2024-07-18:ging-upm:familiarity-ft-v1:AS8ft88F"
    company: "OpenAI" #google or openai
    #ft_dir: "" # for local fine-tunings


  experiment-no-ft-local:
    dataset_path: "path/to/original/dataset.csv"
    dataset_column: "Name of the column containing the words"
    prompt_path: "path/to/prompt.txt"
    # prompt_assistant_path: ""
    model_name: "meta-llama/Llama-3.1-8B-Instruct"
    company: "Local"
    #ft_dir: "" # for local fine-tunings

  experiment-ft-local:
    dataset_path: "path/to/original/dataset.csv"
    dataset_column: "Name of the column containing the words"
    prompt_path: "path/to/prompt.txt"
    # prompt_assistant_path: ""
    model_name: "meta-llama/Llama-3.1-8B-Instruct"
    company: "Local"
    #ft_dir: "familiarity_english_ft_v01_glas_mrc_mean_llama3.1-8B-Instruct_lora" #name of folder where it is the ft model inside finetuning/cache_model or finetuning_final/cache_model


finetuning:
  experiment-ft-v1:
    # create finetuning dataset:
    ft_dataset_path: "path/to/finetuning/dataset.csv"
    train_split_percentage: "Float, percentage of the dataset to use for training"
    random_state: "Integer, random seed, usually 42"
    answer_column: "Name of the column containing the answers"
    prompt_path: "path/to/prompt.txt"
    # prompt_assistant_path: ""
    company: "OpenAI"
    # execute finetuning:
    ft_formatted_dataset_path: "path/to/finetuning/formatted/dataset.jsonl"
    model_name: "OpenAI base model name, e.g., gpt-4o-mini-2024-07-18"
    especial_suffix: "suffix for the fine-tuned model"

  experiment-ft-google:
    # create finetuning dataset:
    ft_dataset_path: "path/to/finetuning/dataset.csv"
    train_split_percentage: "Float, percentage of the dataset to use for training"
    random_state: "Integer, random seed, usually 42"
    answer_column: "Name of the column containing the answers"
    prompt_path: "path/to/prompt.txt"
    # prompt_assistant_path: ""
    company: "Google"
    # execute finetuning:
    model_name: "OpenAI base model name, e.g., gpt-4o-mini-2024-07-18"
    especial_suffix: "suffix for the fine-tuned model"
    project_name: "xx" # only for google models. Obtained from https://console.cloud.google.com/
    bucket_name: "xx" # only for google models. Obtained from https://console.cloud.google.com/
    #A GOOGLE_APPLICATION_CREDENTIALS json file is also needed to access the google account.
